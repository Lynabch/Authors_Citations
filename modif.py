import json
import os
import ijson

# üìç Chemins des fichiers
original_path = "C:/Users/baouc/Documents/GRAPH_DATA/data_graph/dblp_v14.json"
cleaned_json_path = "C:/Users/baouc/Documents/GRAPH_DATA/data_graph/dblp_v14_cleaned.json"
output_path = "C:/Users/baouc/Documents/GRAPH_DATA/data_graph/dblp_cleaned_step1.jsonl"

# üîπ √âtape 1 : Extraire le vrai JSON (de [ √† ])
with open(original_path, "rb") as f:
    content = f.read()
    start = content.find(b"[")
    end = content.rfind(b"]") + 1
    if start == -1 or end == -1:
        raise ValueError("‚ùå Impossible de d√©tecter correctement la structure du JSON.")
    cleaned_content = content[start:end]

# üîπ Sauvegarde dans un nouveau fichier JSON bien form√©
with open(cleaned_json_path, "wb") as f:
    f.write(cleaned_content)

print(f"‚úÖ Fichier nettoy√© temporaire cr√©√© : {cleaned_json_path}")

# üîπ √âtape 2 : Lecture avec ijson + filtrage + nettoyage
champs_utiles = {"id", "title", "year", "venue", "abstract", "authors", "n_citation", "doc_type"}
accepted_doc_types = {"Journal", "Conference"}

with open(cleaned_json_path, "r", encoding="utf-8") as infile, open(output_path, "w", encoding="utf-8") as outfile:
    count = 0
    for article in ijson.items(infile, "item"):
        year = article.get("year")
        doc_type = article.get("doc_type")
        n_citation = article.get("n_citation", 0)

        # üî∏ Condition de filtrage
        if year and int(year) > 2000 and doc_type in accepted_doc_types and n_citation > 0:
            # Ne garder que les champs utiles
            cleaned = {key: article[key] for key in champs_utiles if key in article}

            # Nettoyage des auteurs : suppression de l'ID
            if "authors" in cleaned:
                for author in cleaned["authors"]:
                    author.pop("id", None)

            # √âcriture dans le fichier .jsonl
            outfile.write(json.dumps(cleaned) + "\n")
            count += 1

print(f"‚úÖ {count} articles filtr√©s et nettoy√©s enregistr√©s dans : {output_path}")
