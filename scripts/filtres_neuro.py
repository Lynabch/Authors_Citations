import pandas as pd
from pathlib import Path

# Fichier du graphe de co-auteurs
base_dir = Path(__file__).resolve().parent.parent
data_dir = base_dir / "data_graph"
output_dir = base_dir / "outputs"
# Chargement du fichier JSONL dÃ©jÃ  prÃ©-filtrÃ© (aprÃ¨s 2000, etc.)
input_file = data_dir/"dblp_nodes_after2000.jsonl"
df = pd.read_json(input_file, lines=True)

# Filtres lÃ©gers pour conserver un maximum d'articles valides
# Garder les articles avec un nombre d'auteurs raisonnable (2 Ã  10)
df = df[df["authors"].apply(lambda x: isinstance(x, list) and 2 <= len(x) <= 10)]

# Nettoyer lÃ©gÃ¨rement les noms d'auteurs (au moins deux mots dans le nom)
def clean_authors(authors):
    return [a for a in authors if "name" in a and len(a["name"].split()) >= 2]

df["authors"] = df["authors"].apply(clean_authors)

# Ne garder que les articles avec encore au moins 2 auteurs valides
df = df[df["authors"].apply(lambda x: len(x) > 1)]

# Mots-clÃ©s liÃ©s aux neurosciences
neuro_keywords = ["neuro", "brain", "cortex", "synapse", "neuronal", "neural", "cognitive", "EEG", "fMRI","nervous system", "hippocampus","neuroscience"]

# Fonction de filtrage thÃ©matique sur le titre ou le rÃ©sumÃ©
def contains_neuro_keywords(text):
    if not isinstance(text, str):
        return False
    return any(kw in text.lower() for kw in neuro_keywords)

# Filtrer les articles contenant des mots-clÃ©s neurosciences
df = df[df["title"].apply(contains_neuro_keywords) | df["abstract"].apply(contains_neuro_keywords)]

# Trier par nombre de citations et limiter Ã  2000 articles
df = df.sort_values("n_citation", ascending=False).head(2000)

print(f"ğŸ”¢ Nombre d'articles filtrÃ©s sur la thÃ©matique neuroscience : {len(df)}")
# ğŸ’¾ Enregistrer dans un nouveau fichier JSONL
output_file = output_dir/"dblp_filtered_light.jsonl"
df.to_json(output_file, orient="records", lines=True)

print(f"âœ… Fichier filtrÃ© sauvegardÃ© dans : {output_file}")
print(f"ğŸ”¢ Nombre total d'articles conservÃ©s : {len(df)}")
